{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:04:46.122408: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 16:04:46.282912: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-09 16:04:46.289466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:46.289486: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 16:04:46.319356: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-09 16:04:47.170123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:47.170173: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:47.170179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ansary/anaconda3/envs/bangla/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/01/09 16:04:50] ppocr DEBUG: Namespace(alpha=1.0, benchmark=False, beta=1.0, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/home/ansary/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_fce_box_type='poly', det_limit_side_len=960, det_limit_type='max', det_model_dir='/home/ansary/.paddleocr/whl/det/ml/Multilingual_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_box_type='quad', det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_polygon=False, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_mem=500, help='==SUPPRESS==', image_dir=None, ir_optim=True, label_list=['0', '180'], lang='en', layout=True, layout_label_map=None, layout_path_model='lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config', max_batch_size=10, max_text_length=25, min_subgraph_size=15, mode='structure', ocr=True, ocr_version='PP-OCRv3', output='./output', precision='fp32', process_id=0, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/home/ansary/anaconda3/envs/bangla/lib/python3.8/site-packages/paddleocr/ppocr/utils/en_dict.txt', rec_image_shape='3, 48, 320', rec_model_dir='/home/ansary/.paddleocr/whl/rec/en/en_PP-OCRv3_rec_infer', save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], show_log=True, structure_version='PP-STRUCTURE', table=True, table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=True, use_mp=False, use_onnx=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:04:50.232043: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:50.232108: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:50.232144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:50.233828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:50.233872: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:50.233906: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-09 16:04:50.233914: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m#LOG     :\u001b[0m\u001b[34mLoaded Detector and en-rec \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 16:04:52.047952: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m#LOG     :\u001b[0m\u001b[34mencm loaded\u001b[0m\n",
      "\u001b[32m#LOG     :\u001b[0m\u001b[34mseqm loaded\u001b[0m\n",
      "\u001b[32m#LOG     :\u001b[0m\u001b[34mposm loaded\u001b[0m\n",
      "\u001b[32m#LOG     :\u001b[0m\u001b[34mfusm loaded\u001b[0m\n",
      "\u001b[32m#LOG     :\u001b[0m\u001b[34mLoaded bn-rec\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ocr.ocr import OCR \n",
    "ocr=OCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan  9 16:05:04 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:65:00.0 Off |                  Off |\n",
      "| 30%   41C    P2    71W / 300W |   3909MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1545      G   /usr/lib/xorg/Xorg                 38MiB |\n",
      "|    0   N/A  N/A      1797      G   /usr/bin/gnome-shell                7MiB |\n",
      "|    0   N/A  N/A   3071748      C   python                           3187MiB |\n",
      "|    0   N/A  N/A   3198278      C   ...a3/envs/bangla/bin/python      671MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "(PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/phi/backends/dynload/cudnn.cc:59)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ansary/apis/genOCR/debug.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ansary/apis/genOCR/debug.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img_paths\u001b[39m=\u001b[39m[img \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m glob(\u001b[39m\"\u001b[39m\u001b[39m/home/apsisdev/ansary/OCR_S/memo/ss*.png\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ansary/apis/genOCR/debug.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m img_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/backup/backup/ansary/OCR_S/data/fw.jpeg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ansary/apis/genOCR/debug.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bdf,bn_lines\u001b[39m=\u001b[39mocr(img_path,lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ansary/apis/genOCR/debug.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m bdf\n",
      "File \u001b[0;32m~/apis/genOCR/ocr/ocr.py:90\u001b[0m, in \u001b[0;36mOCR.__call__\u001b[0;34m(self, img_path, lang)\u001b[0m\n\u001b[1;32m     88\u001b[0m img\u001b[39m=\u001b[39mread_img(img_path)\n\u001b[1;32m     89\u001b[0m \u001b[39m# text detection\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m word_boxes,crops\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdet\u001b[39m.\u001b[39;49mdetect(img,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mline_en)\n\u001b[1;32m     91\u001b[0m df,sorted_crops\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_boxes(img,word_boxes,crops)\n\u001b[1;32m     92\u001b[0m \u001b[39m# language classification\u001b[39;00m\n",
      "File \u001b[0;32m~/apis/genOCR/ocr/detector.py:75\u001b[0m, in \u001b[0;36mDetector.detect\u001b[0;34m(self, img, model)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect\u001b[39m(\u001b[39mself\u001b[39m,img,model):\n\u001b[1;32m     72\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m        extract locations and crops\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     result\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mocr(img,rec\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     76\u001b[0m     boxes\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     77\u001b[0m     boxes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msorted_boxes(boxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/bangla/lib/python3.8/site-packages/paddleocr/paddleocr.py:476\u001b[0m, in \u001b[0;36mPaddleOCR.ocr\u001b[0;34m(self, img, det, rec, cls)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[39mreturn\u001b[39;00m [[box\u001b[39m.\u001b[39mtolist(), res] \u001b[39mfor\u001b[39;00m box, res \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(dt_boxes, rec_res)]\n\u001b[1;32m    475\u001b[0m \u001b[39melif\u001b[39;00m det \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rec:\n\u001b[0;32m--> 476\u001b[0m     dt_boxes, elapse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext_detector(img)\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m dt_boxes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bangla/lib/python3.8/site-packages/paddleocr/tools/infer/predict_det.py:215\u001b[0m, in \u001b[0;36mTextDetector.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    213\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_tensors, input_dict)\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_tensor\u001b[39m.\u001b[39;49mcopy_from_cpu(img)\n\u001b[1;32m    216\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mrun()\n\u001b[1;32m    217\u001b[0m     outputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/bangla/lib/python3.8/site-packages/paddle/fluid/inference/wrapper.py:36\u001b[0m, in \u001b[0;36mtensor_copy_from_cpu\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mSupport input type check based on tensor.copy_from_cpu.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray) \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[1;32m     34\u001b[0m                                     \u001b[39mlen\u001b[39m(data) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m     35\u001b[0m                                     \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m)):\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_from_cpu_bind(data)\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIn copy_from_cpu, we only support numpy ndarray and list[str] data type.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: (PreconditionNotMet) Cannot load cudnn shared library. Cannot invoke method cudnnGetVersion.\n  [Hint: cudnn_dso_handle should not be null.] (at /paddle/paddle/phi/backends/dynload/cudnn.cc:59)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "img_paths=[img for img in glob(\"/home/apsisdev/ansary/OCR_S/memo/ss*.png\")]\n",
    "img_path=\"/backup/backup/ansary/OCR_S/data/fw.jpeg\"\n",
    "bdf,bn_lines=ocr(img_path,lang=\"bn\")\n",
    "bdf\n",
    "#edf,en_lines=ocr(img_path,lang=\"en\")\n",
    "    \n",
    "# for img_path in img_paths:\n",
    "#     bn_txt=img_path.replace(\".png\",\"_bn.txt\")\n",
    "#     en_txt=img_path.replace(\".png\",\"_en.txt\")\n",
    "#     with open(bn_txt,\"w+\") as f:\n",
    "#         for line in bn_lines:\n",
    "#             f.write(f\"{line}\\n\")\n",
    "#     with open(en_txt,\"w+\") as f:\n",
    "#         for line in en_lines:\n",
    "#             f.write(f\"{line}\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------------bangla------------------------------------------\")\n",
    "bn_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------------------english------------------------------------------\")\n",
    "en_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf[10:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "126373ade96202fc0d209e372d1dbf9a23bda23100911a41154f9dda3225d3ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
